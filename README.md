# SC4061 Computer Vision

## Topics

-   Imaging
-   Image Enhancement in Spatial Domain
-   Image Enhancement in Frequency Domain

## Imaging

### Imaging Systems

-   Imaging is about capturing a scene's shape (geometry) and brightness (radiometry) to create a 2D representation
-   When a picutre is taken, 3D space turns into 2D space and results in a loss of depth information

#### Basic Components

-   Optical system: focuses light rays from a scene point to converge on one point (lens in camera or eye)
-   Screen: captures light via photoreceptors (retina in eyes, CCD/CMOS in cameras)
-   Aperture: controls light intake (pupil in eyes, adjustable in camera lens)

#### Human Visual System

-   Lens focuses light and is adjusted by muscles
-   Retina has rods for to percieve black/white and cones to perceive color, signals are sent via optic nerve to brain
-   Iris and pupil adjusts automatically, small in bright light and large in dark

#### Digital Cameras

-   Use lenses, sensors and apertures

### Geometric Image Formation

-   Light rays from objects pass through a lens to form an inverted image on the sensor plane

#### Thin Lens Model

-   Can be modelled by a simple thin lens
-   Thin lens has 2 spherical surfaces close to each other and is ideal for point-to-point imaging
    -   For an image to be ideal, it must map a point from object space to its corresponding point in image space
-   Unideal imaging is called abberation
-   Properties
    -   All rays entering lens parallel to optical axis will pass through the focal point on the opposite side (basic property)
    -   All rays entering lens through the focal point on its way to the lens will exit the lens parallel to the optical axis (symmetry property)
    -   All rays entering the lens center will pass straight through the lens, these rays are known as principal rays (consequent property)
-   Lens equations
    -   $\frac{1}{\hat{Z}} + \frac{1}{\hat{z}} = \frac{1}{f}$
        -   $\hat{Z}$ is the distance from object to lens
        -   $\hat{z}$ is the distance from lens to image
        -   $f$ is the focal distance of the lens
-   Magnification equations
    -   $\frac{X}{\hat{Z}} = \frac{x}{\hat{z}}$ and $\frac{Y}{\hat{Z}} = \frac{y}{\hat{z}}$
        -   (X, Y) are coordinates of a point in the object plane
        -   (x, y) are corresponding coordinates in the image plane

#### Depth of Field

-   Refers to the range of depths that scene objects can be at for acceptance imaging
-   Mainly affected by aperture
    -   Smaller aperture will result in larger depth of field
    -   Larger aperture will result in smaller depth of field

### Radiometric Image Formation

-   Deals with brightness/intensity
-   Full model involves light sources, object reflectance, lens collection and sensor response
-   A simplified model is $f(x, y) = i(x, y) \times r(x, y)$
    -   $f(x, y)$ is the image intensity
    -   $i(x, y)$ is the illumination function due to light sources
    -   $r(x, y)$ is the reflectance function due to object shape and albedo

### Digital Image Representation

#### Charge Coupled Device (CCD) Array

-   2D array of photo-diodes
-   Voltage at diodes proportional to image exposure
    -   Exposure = irradiance $\times$ time
    -   Time is the interval that the shutter is open
-   Color is being generated by the Bayer mosaic
    -   B, G, G, R layout
    -   Human eyes are more sensitive to green colour, hence 2 of them present
    -   4 units are then combined together to form 1 pixel in the final image

#### Spatial Sampling

-   Making it discrete
-   Smaller intervals result in higher pixel resolution

#### Quantization

-   Making it digital
-   For digital representation, diode voltages need to be quantized into discrete levels
-   In quantization, usually 8-bit encoding yields 256 levels (0â€“255), sufficient for human perception, as people cannot distinguish beyond this range
    -   More levels would mean greater dynamic resolution
-   An image is discrete after sampling, as it is broken into a grid of pixels
-   After quantization, where pixel values are converted to integers, the image is referred to as digital

#### Image as a Function or Matrix

-   For grayscale images, image intensity is often expressed as a scalar function $f(x, y)$
    -   Can also be viewed as a 2D matrix
-   For color images, it is a vector of three functions $r(x, y)$, $g(x, y)$, $b(x, y)$
    -   Can be viewed as 3D matrix

#### Image Filed Formats

-   GIF is a common 8-bit color indexing and lossless compression format used for web art
-   TIFF is traditionally used for scanned documents, may or may not be compressed
-   PNG is a newer lossless compressed format capable of handling 24-bit images
-   JPEG is a common lossy compression format based on Discrete Cosine Transform (DCT) capable of achieving high compression ratios
-   JPEG2000 is the latest lossy compression format based on Wavelet Transforms

## Image Enhancement in Spatial Domain

### Enhancing Images

-   Enhancement is done when one is not happy with how an image turns out
    -   Can be due to low constrast, noise, blurred, missing parts and more
-   Enhancement can be done using
    -   Point Processing
        -   Each pixel is modified independently based on only its own value
        -   Operations include adjustment of brightness, contrast and gamma correction
    -   Spatial Filtering
        -   Each pixel's new value depends on its neighbours as well as itself, using a mask that slides across an image
        -   Operations include blurring/smoothing, sharpening, edge detection and noise reduction

### Point Processing

-   Key idea: output pixel value = f(input pixel value)
-   $s = T(r)$
    -   $s$ is output pixel intensity
    -   $r$ is input pixel intensity
    -   $T$ is transformation function
-   Same function is applied to all pixels
-   Some functions may be dependent on global statistics

#### Contrast Stretching

-   Maps [r_min, r_max] to [0, 255]
-   Improves visibility under poor illumination

##### Power Law Transformations

-   Functions expressed as $s = c \cdot r^\gamma$
    -   $c$ and $\gamma$ are constants
-   When $\gamma < 1$, it brightens dark areas
    -   Used for MRI enhancement
-   When $\gamma > 1$, it darkens bright areas
    -   Used for aerial image enhancement

#### Histogram Equalization

-   Count how many pixels are there in the picture for each gray scale
-   Histogram reflects frequency (probability distribution)
-   Attempts to flatten the gray-level histogram through a gray-level transformation
    -   Order is preserved (dark stays darker)

### Spatial Filtering

-   Key idea: compute new pixel as weighted sum of neighbours

#### Correlation

-   Correlation uses the weights directly while convolution uses a flipped kernel
-   Formula: $g(x, y) = \sum_{s=-a}^{a} \sum_{t=-b}^{b} w(s, t) \cdot f(x+s, y+t)$

#### Averaging Filter

-   Replace each pixel's value with the average of its neighbours using a kernel
-   Reduces sharp intensity variations and often used to reduce noise
-   Steps
    -   Place kernel over the pixel
    -   Add up all pixel values inside the mask
    -   Divide by total number of pixels in the mask
    -   Assign average to the central pixel

#### Gaussian Filter

-   Kernel values follow Gaussian distribution
-   Pixels closer to the center have higher weight and pixels further away have lower weight
-   Gives a gentler blur than Averaging Filter

#### Median Filter

-   Non-linear filter
-   Used to remove impulse (salt and pepper or speckle) noise from an image
-   Effective in preserving edges
-   Steps
    -   For each pixel in the image, consider a small neighborhood centered around the pixel
    -   Sort all pixel values in that neighborhood
    -   Replace the center pixel value with the median value from the sorted list

#### Deep CNN and Convolution

-   Convolution is the key of image processing
-   Kernels are hard to design
    -   No effective way to do so
    -   No feedback
-   Inception of Deep CNN revolutionized machine learning by enabling kernels to be learned automatically from data, rather than being hand-engineered

## Image Enhancement in Frequency Domain

### Fourier Transform

-   Fourier Transform is a mathematical tool used to transform an image from the spatial domain (where pixels are arranged in a grid of x, y coordinates) to the frequency domain
-   Image is represented as a combination of different frequencies
    -   Low frequencies represent smooth, gradual changes in an image (uniform areas)
    -   High frequencies represent rapid changes (edges, textures, or noise)
-
